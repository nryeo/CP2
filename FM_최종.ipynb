{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stebechoi/CP2/blob/YJ/FM_%EC%B5%9C%EC%A2%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s3rzgNCtJW6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import heapq\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "587CQVoNlF_h",
        "outputId": "7c3b9454-fbb1-4061-8dbc-e53099c983a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기"
      ],
      "metadata": {
        "id": "0DMqzeCledkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/CP2/ml-100k/'\n",
        "r_cols =['user_id','movie_id','rating','timestamp']\n",
        "ratings = pd.read_csv(data_path + 'u.data', sep='\\t',names = r_cols, encoding ='latin-1')\n",
        "item_df = pd.read_csv(data_path + 'u.item', sep='|', encoding='latin-1', header=None,\n",
        "                        names=['movie_id', 'movie_title', 'release_date', 'video_release_date',\n",
        "                               'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
        "                               'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
        "                               'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
        "                               'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
        "item_df = item_df.iloc[:,:2]"
      ],
      "metadata": {
        "id": "BToT_VvetSDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 병합"
      ],
      "metadata": {
        "id": "qOWH-7HoekKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratingcount = ratings.groupby(['movie_id'])['rating'].count().reset_index().rename(columns = {'rating': 'TotalRatingCount'})\n",
        "n_ratings = pd.merge(ratings,ratingcount,how='left',on='movie_id')\n",
        "n_ratings = pd.merge(n_ratings,item_df,how='left', on='movie_id')\n",
        "\n",
        "df_movie_100 = n_ratings[n_ratings['TotalRatingCount']>=100]\n",
        "df_movie_100 = df_movie_100.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "AO0JuoHGqiyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_100 = df_movie_100.drop(['user_id','rating','timestamp','TotalRatingCount'],axis=1)"
      ],
      "metadata": {
        "id": "OlNw8ExRztfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X vector 생성"
      ],
      "metadata": {
        "id": "rg9pqUu4eonp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#user encoding\n",
        "user_dict = {}\n",
        "for i in set(df_movie_100['user_id']):\n",
        "  user_dict[i] = len(user_dict)\n",
        "n_user = len(user_dict)\n",
        "\n",
        "#item encoding\n",
        "item_dict = {}\n",
        "start_point = n_user\n",
        "for i in set(df_movie_100['movie_id']):\n",
        "    item_dict[i] = start_point + len(item_dict)\n",
        "n_item = len(item_dict)\n",
        "start_point += n_item\n",
        "num_x = start_point\n",
        "df_movie_100 = shuffle(df_movie_100, random_state=1)\n",
        "\n",
        "#generate x data\n",
        "#[user_index, movie_index], [user]\n",
        "data = []\n",
        "y = []\n",
        "w0 = np.mean(df_movie_100['rating'])\n",
        "for i in range(len(df_movie_100)):\n",
        "  case = df_movie_100.iloc[i]\n",
        "  x_index = []\n",
        "  x_value = []\n",
        "  x_index.append(user_dict[case['user_id']])\n",
        "  x_value.append(1)\n",
        "  x_index.append(item_dict[case['movie_id']])\n",
        "  x_value.append(1)\n",
        "  data.append([x_index, x_value])\n",
        "  y.append(case['rating'] - w0)\n"
      ],
      "metadata": {
        "id": "wPCFYlv9tvEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FM 모델"
      ],
      "metadata": {
        "id": "OIVMYLV9gCuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RMSE(y_true, y_pred):\n",
        "  return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
        "\n",
        "class FM():\n",
        "  def __init__(self, N, K, data, y, alpha, beta, train_ratio=0.75, iterations=100, tolerance=0.005, l2_reg=True, verbose=True):\n",
        "    self.K = K    #no of latent factors\n",
        "    self.N = N    #no of x variables\n",
        "    self.n_cases = len(data)\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "    self.iterations = iterations\n",
        "    self.l2_reg = l2_reg\n",
        "    self.tolerance = tolerance\n",
        "    self.verbose = verbose\n",
        "\n",
        "    # w 초기화  변수의 편향\n",
        "    self.w = np.random.normal(scale=1./self.N, size=(self.N))\n",
        "    # v 초기화  잠재요인행렬\n",
        "    self.v = np.random.normal(scale=1./self.K, size=(self.N, self.K))\n",
        "    #Train/ Test 분리\n",
        "    cutoff = int(train_ratio* len(data))\n",
        "    self.train_x = data[:cutoff]\n",
        "    self.test_x = data[cutoff:]\n",
        "    self.train_y = y[:cutoff]\n",
        "    self.test_y = y[cutoff:]\n",
        "\n",
        "  #학습 함수\n",
        "  def test(self):\n",
        "    best_RMSE = 10000\n",
        "    best_iteration = 0\n",
        "    training_process = []  #학습과정을 기록\n",
        "    for i in range(self.iterations):\n",
        "      rmse1 = self.sgd(self.train_x, self.train_y)\n",
        "      rmse2 = self.test_rmse(self.test_x, self.test_y)\n",
        "      training_process.append((i,rmse1,rmse2))\n",
        "      if self.verbose:\n",
        "        if(i+1) % 10 == 0:\n",
        "          print(\"Iteration: %d ; Train RMSE = %.6f ; Test RMSE = %.6f\" % (i+1, rmse1, rmse2))\n",
        "      #기존의 RMSE보다 향상되었으면 새로운 RMSE 와 iteration기록\n",
        "      if best_RMSE> rmse2:\n",
        "        best_RMSE = rmse2\n",
        "        best_iteration = i\n",
        "      elif(rmse2 - best_RMSE) >self.tolerance:\n",
        "\n",
        "        break\n",
        "    print(best_iteration, best_RMSE)\n",
        "    return training_process\n",
        "  #sgd 실행\n",
        "  def sgd(self, x_data,  y_data):\n",
        "    y_pred = []\n",
        "    for data, y in zip(x_data, y_data):\n",
        "      x_idx = data[0]\n",
        "      x_0 = np.array(data[1])\n",
        "      x_1 = x_0.reshape(-1,1)\n",
        "\n",
        "      bias_score = np.sum(self.w[x_idx]*x_0)\n",
        "      vx = self.v[x_idx]*(x_1)\n",
        "      sum_vx = np.sum(vx, axis=0)\n",
        "      sum_vx_2 = np.sum(vx*vx, axis=0)\n",
        "      latent_score = 0.5*np.sum(np.square(sum_vx) - sum_vx_2)\n",
        "\n",
        "      y_hat = bias_score + latent_score\n",
        "      y_pred.append(y_hat)\n",
        "      error = y - y_hat\n",
        "\n",
        "      if self.l2_reg:\n",
        "        self.w[x_idx] += error*self.alpha*(x_0 - self.beta*self.w[x_idx])\n",
        "        self.v[x_idx] += error*self.alpha*((x_1)*sum(vx) - (vx*x_1) - self.beta*self.v[x_idx])\n",
        "      else:\n",
        "        self.w[x_idx] += error*self.alpha*x_0\n",
        "        self.v[x_idx] += error*self.alpha*((x_1)*sum(vx) - (vx*x_1))\n",
        "    return RMSE(y_data, y_pred)\n",
        "\n",
        "  def test_rmse(self, x_data, y_data):\n",
        "    y_pred =[]\n",
        "    for data, y in zip(x_data, y_data):\n",
        "      y_hat = self.predict(data[0], data[1])\n",
        "      y_pred.append(y_hat)\n",
        "    return RMSE(y_data, y_pred)\n",
        "  \n",
        "  def predict(self, idx, x):\n",
        "    x_0 = np.array(x)\n",
        "    x_1 = x_0.reshape(-1,1)\n",
        "    bias_score =  np.sum(self.w[idx]*x_0)\n",
        "\n",
        "    vx = self.v[idx]*(x_1)\n",
        "    sum_vx = np.sum(vx, axis=0)\n",
        "    sum_vx_2 = np.sum(vx*vx,axis=0)\n",
        "    latent_score = 0.5*np.sum(np.square(sum_vx)-sum_vx_2)\n",
        "\n",
        "    y_hat = bias_score + latent_score\n",
        "    return y_hat\n"
      ],
      "metadata": {
        "id": "PqesN8BAuQQ5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K=350\n",
        "fm1 = FM(num_x, K, data, y, alpha=0.001, beta=0.05, train_ratio=0.75, iterations=600, tolerance=0.0005, l2_reg=True, verbose=True)\n",
        "result = fm1.test()"
      ],
      "metadata": {
        "id": "OPZk9aGCgafI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "for K in range(100,201,20):\n",
        "  print('K :',K)\n",
        "  fm1 = FM(num_x, K , data, y, alpha=0.001, beta=0.05, train_ratio=0.75, iterations=600, tolerance=0.0005, l2_reg=True, verbose=True)\n",
        "  result = fm1.test()\n",
        "  results.append(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "FzrKrS3Thuwr",
        "outputId": "f7e8aed0-a6a4-4f4b-c8c5-d554f04df791"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K : 100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cbe62b10529d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'K :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mfm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-80b8dc7868ea>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtraining_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#학습과정을 기록\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mrmse1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0mrmse2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mtraining_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmse1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmse2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-80b8dc7868ea>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(self, x_data, y_data)\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_reg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommendations(user_id, k):\n",
        "  user_predictions = []\n",
        "  user_index = user_dict[user_id]\n",
        "  for movie_id, item_index in item_dict.items():\n",
        "      x_index = [user_index, item_index]\n",
        "      x_value = [1, 1]\n",
        "      predicted_rating = fm1.predict(x_index, x_value)\n",
        "      user_predictions.append((movie_id, predicted_rating))\n",
        "  \n",
        "  top_k_recommendations = heapq.nlargest(k, user_predictions, key=lambda x: x[1])\n",
        "  id_list = [movie_id for movie_id, _ in top_k_recommendations]\n",
        "  rec_list=[]\n",
        "  for i,r in movie_100.iterrows():\n",
        "    if i in id_list:\n",
        "      rec_list.append(r['movie_title'])\n",
        "  return rec_list"
      ],
      "metadata": {
        "id": "EPMgmmgjlN6N"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations(1,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie49Hk_4wz30",
        "outputId": "a6e1a4c3-4037-4e89-ace4-d24d115019a7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Star Trek III: The Search for Spock (1984)',\n",
              " 'Kolya (1996)',\n",
              " 'Pulp Fiction (1994)',\n",
              " 'Mimic (1997)',\n",
              " 'Ghost (1990)']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_recommendations(user_id, k):\n",
        "    user_predictions = []\n",
        "    user_index = user_dict[user_id]\n",
        "    for movie_id, item_index in item_dict.items():\n",
        "        x_index = [user_index, item_index]\n",
        "        x_value = [1, 1]\n",
        "        predicted_rating = fm1.predict(x_index, x_value)\n",
        "        user_predictions.append((movie_id, predicted_rating))\n",
        "    \n",
        "    top_k_recommendations = heapq.nlargest(k, user_predictions, key=lambda x: x[1])\n",
        "    return [movie_id for movie_id, _ in top_k_recommendations]"
      ],
      "metadata": {
        "id": "3mV1Qoxp28VR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_at_k(user_id, k):\n",
        "    user_ratings = df_movie_100[df_movie_100['user_id'] == user_id]\n",
        "    test_ratings = user_ratings.sample(frac=0.2, random_state=1)\n",
        "    top_k_recommendations = get_top_k_recommendations(user_id, k)\n",
        "\n",
        "    relevant_items = set(test_ratings[test_ratings['rating'] >= 4]['movie_id'].values)\n",
        "    recommended_relevant_items = [movie_id for movie_id in top_k_recommendations if movie_id in relevant_items]\n",
        "    \n",
        "    precision = len(recommended_relevant_items) / k\n",
        "    return precision\n",
        "\n",
        "\n",
        "k = 10\n",
        "all_user_precision_at_k = [precision_at_k(user_id, k) for user_id in user_dict.keys()]\n",
        "mean_precision_at_k = np.mean(all_user_precision_at_k)\n",
        "print(\"Precision@{}: {:.4f}\".format(k, mean_precision_at_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAktaTfV0-Vv",
        "outputId": "77436064-34e4-47fc-8459-5035d42f5dab"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10: 0.0863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_at_k(user_id, k):\n",
        "    user_ratings = df_movie_100[df_movie_100['user_id'] == user_id]\n",
        "    test_ratings = user_ratings.sample(frac=0.2, random_state=1)\n",
        "    top_k_recommendations = get_top_k_recommendations(user_id, k)\n",
        "\n",
        "    relevant_items = set(test_ratings[test_ratings['rating'] >= 4]['movie_id'].values)\n",
        "    recommended_relevant_items = [movie_id for movie_id in top_k_recommendations if movie_id in relevant_items]\n",
        "    \n",
        "    recall = len(recommended_relevant_items) / len(relevant_items) if relevant_items else 0\n",
        "    return recall\n",
        "\n",
        "\n",
        "k = 10\n",
        "all_user_recall_at_k = [recall_at_k(user_id, k) for user_id in user_dict.keys()]\n",
        "mean_recall_at_k = np.mean(all_user_recall_at_k)\n",
        "print(\"Recall@{}: {:.4f}\".format(k, mean_recall_at_k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWubxAuH3Uqh",
        "outputId": "f48fb3f4-3f89-41aa-c4ca-5100dd54cbe8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall@10: 0.0893\n"
          ]
        }
      ]
    }
  ]
}