{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stebechoi/CP2/blob/YJ/FM%E1%84%87%E1%85%A7%E1%86%AB%E1%84%89%E1%85%AE%E1%84%8E%E1%85%AE%E1%84%80%E1%85%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-s3rzgNCtJW6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeSDEaXfkElH",
        "outputId": "08016c45-8745-4bde-a4c6-7fdb2c84bbf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BToT_VvetSDP"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/CP2/ml-100k/'\n",
        "r_cols =['userId','movieId','rating','timestamp']\n",
        "ratings = pd.read_csv(data_path + 'u.data', sep='\\t',names = r_cols, encoding ='latin-1')\n",
        "\n",
        "item_df = pd.read_csv(data_path + 'u.item', sep='|', encoding='latin-1', header=None,\n",
        "                        names=['movieId', 'movie_title', 'release_date', 'video_release_date',\n",
        "                               'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
        "                               'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
        "                               'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
        "                               'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
        "\n",
        "users_df = pd.read_csv(data_path + 'u.user', sep='|', names = ['userId', 'age', 'gender', 'occupation', 'zip_code'])\n",
        "users_df = users_df.drop(['zip_code','age','occupation'],axis=1)\n",
        "item_df = item_df.drop(['movie_title','release_date', 'video_release_date', 'IMDb_URL'], axis=1)\n",
        "ratings = ratings.drop('timestamp',axis=1)\n",
        "# item_df = item_df.iloc[:,:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wPCFYlv9tvEw"
      },
      "outputs": [],
      "source": [
        "#user encoding\n",
        "user_dict = {}\n",
        "for i in set(ratings['userId']):\n",
        "  user_dict[i] = len(user_dict)\n",
        "n_user = len(user_dict)\n",
        "\n",
        "#item encoding\n",
        "item_dict = {}\n",
        "start_point = n_user\n",
        "for i in set(ratings['movieId']):\n",
        "    item_dict[i] = start_point + len(item_dict)\n",
        "n_item = len(item_dict)\n",
        "start_point += n_item\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#gender\n",
        "gender_dict = {}\n",
        "for i in set(users_df['gender']):\n",
        "  gender_dict[i] = start_point + len(gender_dict)\n",
        "n_gender = len(gender_dict)\n",
        "start_point += n_gender\n",
        "\n",
        "#genre\n",
        "genre_dict = {}\n",
        "genre = ['unknown', 'Action', 'Adventure', 'Animation',\n",
        "         'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
        "         'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
        "         'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "for i in genre:\n",
        "  genre_dict[i] = start_point + len(genre_dict)\n",
        "n_genre = len(genre_dict)\n",
        "start_point += n_genre\n",
        "num_x = start_point\n",
        "\n",
        "x = pd.merge(ratings, item_df, how='outer', on='movieId')\n",
        "x = pd.merge(x, users_df, how='outer', on='userId')\n",
        "x = shuffle(x,random_state=1)\n",
        "\n",
        "#generate x data\n",
        "#[user_index, movie_index], [user]\n",
        "data = []\n",
        "y = []\n",
        "w0 = np.mean(ratings['rating'])\n",
        "for i in range(len(x)):\n",
        "  case = x.iloc[i]\n",
        "  x_index = []\n",
        "  x_value = []\n",
        "  x_index.append(user_dict[case['userId']])\n",
        "  x_value.append(1)\n",
        "  x_index.append(item_dict[case['movieId']])\n",
        "  x_value.append(1)\n",
        "  x_index.append(gender_dict[case['gender']])\n",
        "  x_value.append(1)\n",
        "  for j in genre:\n",
        "    if case[j] == 1:\n",
        "      x_index.append(genre_dict[j])\n",
        "      x_value.append(1)\n",
        "  data.append([x_index, x_value])\n",
        "  y.append(case['rating'] - w0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PqesN8BAuQQ5"
      },
      "outputs": [],
      "source": [
        "def RMSE(y_true, y_pred):\n",
        "  return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
        "\n",
        "class FM():\n",
        "  def __init__(self, N, K, data, y, alpha, beta,n_user,n_item, train_ratio=0.75, iterations=100, tolerance=0.005, l2_reg=True, verbose=True):\n",
        "    self.K = K    #no of latent factors\n",
        "    self.N = N    #no of x variables\n",
        "    self.n_cases = len(data)\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "    self.n_user = n_user\n",
        "    self.n_item = n_item\n",
        "    self.iterations = iterations\n",
        "    self.l2_reg = l2_reg\n",
        "    self.tolerance = tolerance\n",
        "    self.verbose = verbose\n",
        "\n",
        "    # w 초기화  변수의 편향\n",
        "    self.w = np.random.normal(scale=1./self.N, size=(self.N))\n",
        "    # v 초기화  잠재요인행렬\n",
        "    self.v = np.random.normal(scale=1./self.K, size=(self.N, self.K))\n",
        "    #Train/ Test 분리\n",
        "    cutoff = int(train_ratio* len(data))\n",
        "    self.train_x = data[:cutoff]\n",
        "    self.test_x = data[cutoff:]\n",
        "    self.train_y = y[:cutoff]\n",
        "    self.test_y = y[cutoff:]\n",
        "\n",
        "  #학습 함수\n",
        "  def test(self):\n",
        "    best_RMSE = 10000\n",
        "    best_iteration = 0\n",
        "    training_process = []  #학습과정을 기록\n",
        "    for i in range(self.iterations):\n",
        "      rmse1 = self.sgd(self.train_x, self.train_y)\n",
        "      rmse2 = self.test_rmse(self.test_x, self.test_y)\n",
        "      training_process.append((i,rmse1,rmse2))\n",
        "      if self.verbose:\n",
        "        if(i+1) % 10 == 0:\n",
        "          print(\"Iteration: %d ; Train RMSE = %.6f ; Test RMSE = %.6f\" % (i+1, rmse1, rmse2))\n",
        "      #기존의 RMSE보다 향상되었으면 새로운 RMSE 와 iteration기록\n",
        "      if best_RMSE> rmse2:\n",
        "        best_RMSE = rmse2\n",
        "        best_iteration = i\n",
        "      elif(rmse2 - best_RMSE) >self.tolerance:\n",
        "\n",
        "        break\n",
        "    print(best_iteration, best_RMSE)\n",
        "    return training_process\n",
        "  #sgd 실행\n",
        "  def sgd(self, x_data,  y_data):\n",
        "    y_pred = []\n",
        "    for data, y in zip(x_data, y_data):\n",
        "      x_idx = data[0]\n",
        "      x_0 = np.array(data[1])\n",
        "      x_1 = x_0.reshape(-1,1)\n",
        "\n",
        "      bias_score = np.sum(self.w[x_idx]*x_0)\n",
        "      vx = self.v[x_idx]*(x_1)\n",
        "      sum_vx = np.sum(vx, axis=0)\n",
        "      sum_vx_2 = np.sum(vx*vx, axis=0)\n",
        "      latent_score = 0.5*np.sum(np.square(sum_vx) - sum_vx_2)\n",
        "\n",
        "      y_hat = bias_score + latent_score\n",
        "      y_pred.append(y_hat)\n",
        "      error = y - y_hat\n",
        "\n",
        "      if self.l2_reg:\n",
        "        self.w[x_idx] += error*self.alpha*(x_0 - self.beta*self.w[x_idx])\n",
        "        self.v[x_idx] += error*self.alpha*((x_1)*sum(vx) - (vx*x_1) - self.beta*self.v[x_idx])\n",
        "      else:\n",
        "        self.w[x_idx] += error*self.alpha*x_0\n",
        "        self.v[x_idx] += error*self.alpha*((x_1)*sum(vx) - (vx*x_1))\n",
        "    return RMSE(y_data, y_pred)\n",
        "\n",
        "  def test_rmse(self, x_data, y_data):\n",
        "    y_pred =[]\n",
        "    for data, y in zip(x_data, y_data):\n",
        "      y_hat = self.predict(data[0], data[1])\n",
        "      y_pred.append(y_hat)\n",
        "    return RMSE(y_data, y_pred)\n",
        "\n",
        "  def full_predict(self,x_data,y_data):\n",
        "    y_pred=[]\n",
        "    for data,y in zip(x_data, y_data):\n",
        "      y_hat = self.predict(data[0], data[1])\n",
        "      y_pred.append(y_hat)\n",
        "    return y_pred\n",
        "\n",
        "  \n",
        "  def predict(self, idx, x):\n",
        "    x_0 = np.array(x)\n",
        "    x_1 = x_0.reshape(-1,1)\n",
        "    bias_score =  np.sum(self.w[idx]*x_0)\n",
        "\n",
        "    vx = self.v[idx]*(x_1)\n",
        "    sum_vx = np.sum(vx, axis=0)\n",
        "    sum_vx_2 = np.sum(vx*vx,axis=0)\n",
        "    latent_score = 0.5*np.sum(np.square(sum_vx)-sum_vx_2)\n",
        "\n",
        "    y_hat = bias_score + latent_score\n",
        "    return y_hat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT1nd01LMxHS",
        "outputId": "3ec95d3a-ed4e-4427-8c5f-1628d5f8de32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 10 ; Train RMSE = 0.910834 ; Test RMSE = 0.943315\n",
            "Iteration: 20 ; Train RMSE = 0.882020 ; Test RMSE = 0.939918\n",
            "Iteration: 30 ; Train RMSE = 0.859613 ; Test RMSE = 0.940279\n",
            "23 0.9397833270599084\n"
          ]
        }
      ],
      "source": [
        "K=350\n",
        "fm1 = FM(num_x, K, data, y, alpha=0.0014, beta=0.075,n_user=n_user,n_item=n_item, train_ratio=0.75, iterations=100, tolerance=0.0005, l2_reg=True, verbose=True)\n",
        "result = fm1.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "장르 젠더 직업 나이 rmse 0.93  \n",
        "장르 젠더 rmse 0.939 더올라감\n"
      ],
      "metadata": {
        "id": "wdu0tqb2kfpj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}